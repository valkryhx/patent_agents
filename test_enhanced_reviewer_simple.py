#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆå¢å¼ºå®¡æ ¸æ™ºèƒ½ä½“æµ‹è¯•
"""

import asyncio
import logging
import aiohttp
import json
from datetime import datetime
from typing import Dict, List, Any

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimpleDuckDuckGoSearcher:
    """ç®€åŒ–ç‰ˆDuckDuckGoæ£€ç´¢å™¨"""
    
    def __init__(self):
        self.base_url = "https://api.duckduckgo.com/"
        self.session = None
    
    async def _get_session(self):
        """è·å–aiohttp session"""
        if self.session is None:
            self.session = aiohttp.ClientSession()
        return self.session
    
    async def search(self, query: str, max_results: int = 5) -> List[Dict[str, Any]]:
        """æ‰§è¡Œæ£€ç´¢"""
        try:
            session = await self._get_session()
            
            # æ„å»ºæ£€ç´¢å‚æ•°
            params = {
                "q": query,
                "format": "json",
                "no_html": "1",
                "skip_disambig": "1"
            }
            
            async with session.get(self.base_url, params=params) as response:
                if response.status in [200, 202]:  # DuckDuckGo APIè¿”å›202æ˜¯æ­£å¸¸çš„
                    # DuckDuckGoè¿”å›çš„Content-Typeæ˜¯application/x-javascriptï¼Œéœ€è¦æ‰‹åŠ¨è§£æ
                    text = await response.text()
                    try:
                        data = json.loads(text)
                        return self._parse_search_results(data, max_results)
                    except json.JSONDecodeError as e:
                        logger.error(f"JSONè§£æå¤±è´¥: {e}")
                        return []
                else:
                    logger.error(f"DuckDuckGoæ£€ç´¢å¤±è´¥: {response.status}")
                    return []
                    
        except Exception as e:
            logger.error(f"DuckDuckGoæ£€ç´¢å¼‚å¸¸: {e}")
            return []
    
    def _parse_search_results(self, data: Dict, max_results: int) -> List[Dict[str, Any]]:
        """è§£ææ£€ç´¢ç»“æœ"""
        results = []
        
        # è§£æç›¸å…³ä¸»é¢˜
        if "RelatedTopics" in data:
            for topic in data["RelatedTopics"][:max_results]:
                if isinstance(topic, dict) and "Text" in topic:
                    results.append({
                        "title": topic.get("Text", ""),
                        "url": topic.get("FirstURL", ""),
                        "content": topic.get("Text", ""),
                        "source": "DuckDuckGo RelatedTopics"
                    })
        
        # è§£ææ‘˜è¦
        if "Abstract" in data and data["Abstract"]:
            results.append({
                "title": data.get("AbstractText", ""),
                "url": data.get("AbstractURL", ""),
                "content": data["Abstract"],
                "source": "DuckDuckGo Abstract"
            })
        
        # è§£æInfoboxä¿¡æ¯
        if "Infobox" in data and data["Infobox"]:
            infobox = data["Infobox"]
            if "content" in infobox:
                for item in infobox["content"][:max_results]:
                    if isinstance(item, dict) and "label" in item and "value" in item:
                        results.append({
                            "title": f"{item['label']}: {item['value']}",
                            "url": "",
                            "content": f"{item['label']}: {item['value']}",
                            "source": "DuckDuckGo Infobox"
                        })
        
        # è§£æResults
        if "Results" in data and data["Results"]:
            for result in data["Results"][:max_results]:
                if isinstance(result, dict) and "Text" in result:
                    results.append({
                        "title": result.get("Text", ""),
                        "url": result.get("FirstURL", ""),
                        "content": result.get("Text", ""),
                        "source": "DuckDuckGo Results"
                    })
        
        return results[:max_results]
    
    async def close(self):
        """å…³é—­session"""
        if self.session:
            await self.session.close()

class SimpleEnhancedReviewer:
    """ç®€åŒ–ç‰ˆå¢å¼ºå®¡æ ¸æ™ºèƒ½ä½“"""
    
    def __init__(self):
        self.searcher = SimpleDuckDuckGoSearcher()
    
    async def comprehensive_review(self, 
                                 chapter_3_content: str, 
                                 chapter_4_content: str, 
                                 chapter_5_content: str,
                                 topic: str,
                                 search_results: Dict) -> Dict[str, Any]:
        """ç»¼åˆå®¡æ ¸ï¼šç»“åˆå‰ä¸‰ç« å†…å®¹ï¼Œæ·±åº¦æ£€ç´¢ï¼Œæå‡ºæ‰¹åˆ¤æ€§æ„è§"""
        
        try:
            # 1. æ·±åº¦æ£€ç´¢ç¬¬äº”ç« ç›¸å…³å†…å®¹
            chapter_5_keywords = self._extract_chapter_5_keywords(chapter_5_content)
            deep_search_results = await self._deep_search_chapter_5(chapter_5_keywords, topic)
            
            # 2. ä¸‰æ€§å®¡æ ¸ï¼ˆç»“åˆå‰ä¸‰ç« å†…å®¹ï¼‰
            novelty_analysis = self._analyze_novelty(chapter_3_content, chapter_5_content, deep_search_results)
            inventiveness_analysis = self._analyze_inventiveness(chapter_4_content, chapter_5_content, deep_search_results)
            utility_analysis = self._analyze_utility(chapter_5_content, deep_search_results)
            
            # 3. æ‰¹åˆ¤æ€§åˆ†æ
            critical_analysis = self._critical_analysis(chapter_3_content, chapter_4_content, chapter_5_content, deep_search_results)
            
            # 4. æ”¹è¿›å»ºè®®
            improvement_suggestions = self._generate_improvement_suggestions(
                chapter_3_content, chapter_4_content, chapter_5_content, 
                novelty_analysis, inventiveness_analysis, utility_analysis, critical_analysis
            )
            
            # 5. æ€»ä½“è¯„ä¼°
            overall_assessment = self._generate_overall_assessment(
                novelty_analysis, inventiveness_analysis, utility_analysis, critical_analysis
            )
            
            return {
                "deep_search_results": deep_search_results,
                "novelty_analysis": novelty_analysis,
                "inventiveness_analysis": inventiveness_analysis,
                "utility_analysis": utility_analysis,
                "critical_analysis": critical_analysis,
                "improvement_suggestions": improvement_suggestions,
                "overall_assessment": overall_assessment
            }
            
        except Exception as e:
            logger.error(f"ç»¼åˆå®¡æ ¸å¤±è´¥: {e}")
            return self._generate_fallback_review_results()
    
    def _extract_chapter_5_keywords(self, chapter_5_content: str) -> List[str]:
        """æå–ç¬¬äº”ç« å…³é”®æŠ€æœ¯è¯ç”¨äºæ·±åº¦æ£€ç´¢"""
        # ç®€å•çš„å…³é”®è¯æå–
        common_tech_keywords = [
            "ç®—æ³•", "ç³»ç»Ÿ", "æ–¹æ³•", "æŠ€æœ¯", "åˆ›æ–°", "æ¶æ„", "å®ç°", "ä¼˜åŒ–", 
            "å¤„ç†", "åˆ†æ", "è®¡ç®—", "æ¨¡å‹", "æ•°æ®", "æ¥å£", "åè®®", "æœºåˆ¶",
            "æ™ºèƒ½", "å‡½æ•°", "å‚æ•°", "è°ƒç”¨", "é‡è¯•", "æ¨æ–­", "è¯­ä¹‰", "ç†è§£"
        ]
        
        keywords = []
        for keyword in common_tech_keywords:
            if keyword in chapter_5_content:
                keywords.append(keyword)
        
        return keywords[:10]  # é™åˆ¶æ•°é‡
    
    async def _deep_search_chapter_5(self, keywords: List[str], topic: str) -> Dict[str, Any]:
        """å¯¹ç¬¬äº”ç« å†…å®¹è¿›è¡Œæ·±åº¦æ£€ç´¢"""
        search_results = {}
        
        for keyword in keywords[:5]:  # é™åˆ¶æ£€ç´¢æ•°é‡é¿å…è¿‡è½½
            try:
                # æ„å»ºæ£€ç´¢æŸ¥è¯¢
                search_query = f"{topic} {keyword} ä¸“åˆ© æŠ€æœ¯æ–¹æ¡ˆ"
                results = await self.searcher.search(search_query, max_results=3)
                search_results[keyword] = results
                
                # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
                await asyncio.sleep(1)
                
            except Exception as e:
                logger.error(f"æ£€ç´¢å…³é”®è¯ {keyword} å¤±è´¥: {e}")
                search_results[keyword] = []
        
        return search_results
    
    def _analyze_novelty(self, chapter_3_content: str, chapter_5_content: str, search_results: Dict) -> Dict[str, Any]:
        """åˆ†ææ–°é¢–æ€§ï¼ˆç»“åˆç¬¬ä¸‰ç« ç°æœ‰æŠ€æœ¯ï¼‰"""
        # ç®€å•çš„åˆ†æé€»è¾‘
        novelty_score = 75  # é»˜è®¤è¯„åˆ†
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤å†…å®¹
        if chapter_3_content and chapter_5_content:
            # ç®€å•çš„é‡å¤åº¦æ£€æŸ¥
            common_words = set(chapter_3_content.split()) & set(chapter_5_content.split())
            if len(common_words) > 50:  # å¦‚æœå…±åŒè¯æ±‡è¿‡å¤šï¼Œé™ä½æ–°é¢–æ€§è¯„åˆ†
                novelty_score = 65
        
        return {
            "analysis": f"åŸºäºç¬¬ä¸‰ç« ç°æœ‰æŠ€æœ¯å’Œç¬¬äº”ç« æŠ€æœ¯æ–¹æ¡ˆçš„å¯¹æ¯”åˆ†æï¼ŒæŠ€æœ¯æ–¹æ¡ˆå…·æœ‰ä¸­ç­‰ç¨‹åº¦çš„æ–°é¢–æ€§ã€‚",
            "novelty_score": novelty_score,
            "risk_level": "ä¸­ç­‰",
            "improvement_suggestions": ["å¢å¼ºæŠ€æœ¯æ–¹æ¡ˆçš„ç‹¬ç‰¹æ€§", "æ˜ç¡®ä¸ç°æœ‰æŠ€æœ¯çš„åŒºåˆ«"],
            "timestamp": datetime.now().isoformat()
        }
    
    def _analyze_inventiveness(self, chapter_4_content: str, chapter_5_content: str, search_results: Dict) -> Dict[str, Any]:
        """åˆ†æåˆ›é€ æ€§ï¼ˆç»“åˆç¬¬å››ç« æŠ€æœ¯é—®é¢˜ï¼‰"""
        # ç®€å•çš„åˆ†æé€»è¾‘
        inventiveness_score = 80
        
        # æ£€æŸ¥æ˜¯å¦è§£å†³äº†ç¬¬å››ç« æå‡ºçš„é—®é¢˜
        if chapter_4_content and chapter_5_content:
            # ç®€å•çš„å…³é”®è¯åŒ¹é…
            problem_keywords = ["é—®é¢˜", "å›°éš¾", "ä¸è¶³", "ç¼ºé™·", "é™åˆ¶"]
            solution_keywords = ["è§£å†³", "æ”¹è¿›", "ä¼˜åŒ–", "åˆ›æ–°", "æ–¹æ¡ˆ"]
            
            problem_count = sum(1 for word in problem_keywords if word in chapter_4_content)
            solution_count = sum(1 for word in solution_keywords if word in chapter_5_content)
            
            if solution_count > problem_count:
                inventiveness_score = 85
        
        return {
            "analysis": f"åŸºäºç¬¬å››ç« æŠ€æœ¯é—®é¢˜å’Œç¬¬äº”ç« æŠ€æœ¯æ–¹æ¡ˆçš„åˆ†æï¼ŒæŠ€æœ¯æ–¹æ¡ˆå…·æœ‰è¾ƒå¼ºçš„åˆ›é€ æ€§ã€‚",
            "inventiveness_score": inventiveness_score,
            "problem_difficulty": "é«˜",
            "improvement_suggestions": ["å¢å¼ºæŠ€æœ¯æ–¹æ¡ˆçš„åˆ›æ–°æ€§", "æ˜ç¡®æŠ€æœ¯è´¡çŒ®"],
            "timestamp": datetime.now().isoformat()
        }
    
    def _analyze_utility(self, chapter_5_content: str, search_results: Dict) -> Dict[str, Any]:
        """åˆ†æå®ç”¨æ€§"""
        # ç®€å•çš„åˆ†æé€»è¾‘
        utility_score = 85
        
        # æ£€æŸ¥æŠ€æœ¯æ–¹æ¡ˆçš„å¯è¡Œæ€§
        feasibility_keywords = ["å®ç°", "åº”ç”¨", "éƒ¨ç½²", "ä½¿ç”¨", "åˆ¶é€ "]
        feasibility_count = sum(1 for word in feasibility_keywords if word in chapter_5_content)
        
        if feasibility_count > 3:
            utility_score = 90
        
        return {
            "analysis": f"åŸºäºç¬¬äº”ç« æŠ€æœ¯æ–¹æ¡ˆçš„åˆ†æï¼ŒæŠ€æœ¯æ–¹æ¡ˆå…·æœ‰è¾ƒå¼ºçš„å®ç”¨æ€§ã€‚",
            "utility_score": utility_score,
            "feasibility": "é«˜",
            "market_potential": "è‰¯å¥½",
            "improvement_suggestions": ["å¢å¼ºå®ç”¨æ€§", "æ˜ç¡®åº”ç”¨åœºæ™¯"],
            "timestamp": datetime.now().isoformat()
        }
    
    def _critical_analysis(self, chapter_3_content: str, chapter_4_content: str, chapter_5_content: str, search_results: Dict) -> Dict[str, Any]:
        """æ‰¹åˆ¤æ€§åˆ†æ"""
        # ç®€å•çš„æ‰¹åˆ¤æ€§åˆ†æ
        critical_score = 70
        
        # æ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§
        if chapter_3_content and chapter_4_content and chapter_5_content:
            # ç®€å•çš„é€»è¾‘æ£€æŸ¥
            if len(chapter_5_content) > len(chapter_3_content) + len(chapter_4_content):
                critical_score = 75  # æŠ€æœ¯æ–¹æ¡ˆå†…å®¹å……åˆ†
        
        return {
            "analysis": f"åŸºäºå‰ä¸‰ç« å†…å®¹çš„æ‰¹åˆ¤æ€§åˆ†æï¼ŒæŠ€æœ¯æ–¹æ¡ˆå…·æœ‰ä¸­ç­‰ç¨‹åº¦çš„é€»è¾‘ä¸€è‡´æ€§å’Œå®ç°å¯è¡Œæ€§ã€‚",
            "critical_score": critical_score,
            "risk_level": "ä¸­ç­‰",
            "implementation_difficulty": "ä¸­ç­‰",
            "improvement_space": "è¾ƒå¤§",
            "improvement_suggestions": ["å¢å¼ºé€»è¾‘ä¸€è‡´æ€§", "é™ä½æŠ€æœ¯é£é™©"],
            "timestamp": datetime.now().isoformat()
        }
    
    def _generate_improvement_suggestions(self, 
                                        chapter_3_content: str, 
                                        chapter_4_content: str, 
                                        chapter_5_content: str,
                                        novelty_analysis: Dict,
                                        inventiveness_analysis: Dict,
                                        utility_analysis: Dict,
                                        critical_analysis: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = [
            "å¢å¼ºæŠ€æœ¯æ–¹æ¡ˆä¸ç°æœ‰æŠ€æœ¯çš„åŒºåˆ«åº¦",
            "æ˜ç¡®æŠ€æœ¯æ–¹æ¡ˆçš„åˆ›æ–°ç‚¹å’Œä¼˜åŠ¿",
            "æä¾›æ›´è¯¦ç»†çš„æŠ€æœ¯å®ç°æ–¹æ¡ˆ",
            "å¢åŠ åº”ç”¨åœºæ™¯å’Œæ•ˆæœåˆ†æ",
            "å®Œå–„é£é™©æ§åˆ¶å’Œé”™è¯¯å¤„ç†æœºåˆ¶"
        ]
        
        return {
            "suggestions": "åŸºäºå…¨é¢åˆ†æï¼Œå»ºè®®ä»æŠ€æœ¯ç‹¬ç‰¹æ€§ã€åˆ›æ–°æ€§ã€å®ç”¨æ€§ç­‰æ–¹é¢è¿›è¡Œæ”¹è¿›ã€‚",
            "priority_levels": ["é«˜", "ä¸­", "ä½"],
            "expected_effects": ["æå‡ä¸“åˆ©è´¨é‡", "å¢å¼ºåˆ›æ–°æ€§", "é™ä½é£é™©"],
            "implementation_steps": ["ç«‹å³å®æ–½", "åˆ†é˜¶æ®µå®æ–½", "é•¿æœŸè§„åˆ’"],
            "timestamp": datetime.now().isoformat()
        }
    
    def _generate_overall_assessment(self, 
                                   novelty_analysis: Dict,
                                   inventiveness_analysis: Dict,
                                   utility_analysis: Dict,
                                   critical_analysis: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆæ€»ä½“è¯„ä¼°"""
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        novelty_score = novelty_analysis.get("novelty_score", 70)
        inventiveness_score = inventiveness_analysis.get("inventiveness_score", 75)
        utility_score = utility_analysis.get("utility_score", 80)
        critical_score = critical_analysis.get("critical_score", 70)
        
        overall_score = (novelty_score + inventiveness_score + utility_score + critical_score) // 4
        
        # ç¡®å®šè´¨é‡ç­‰çº§
        if overall_score >= 85:
            quality_grade = "A"
        elif overall_score >= 75:
            quality_grade = "B"
        elif overall_score >= 65:
            quality_grade = "C"
        else:
            quality_grade = "D"
        
        return {
            "assessment": f"åŸºäºæ–°é¢–æ€§ã€åˆ›é€ æ€§ã€å®ç”¨æ€§ã€æ‰¹åˆ¤æ€§å››ä¸ªç»´åº¦çš„ç»¼åˆè¯„ä¼°ï¼Œä¸“åˆ©è´¨é‡ç­‰çº§ä¸º{quality_grade}ã€‚",
            "overall_score": overall_score,
            "quality_grade": quality_grade,
            "risk_level": "ä¸­ç­‰",
            "improvement_potential": "è‰¯å¥½",
            "market_prospect": "è‰¯å¥½",
            "application_recommendation": "å»ºè®®ç”³è¯·",
            "decision_suggestion": "ç»§ç»­å®Œå–„åç”³è¯·",
            "next_actions": ["å®Œå–„æŠ€æœ¯æ–¹æ¡ˆ", "å¢å¼ºåˆ›æ–°æ€§", "é™ä½é£é™©"],
            "timestamp": datetime.now().isoformat()
        }
    
    def _generate_fallback_review_results(self) -> Dict[str, Any]:
        """ç”Ÿæˆfallbackå®¡æ ¸ç»“æœ"""
        return {
            "deep_search_results": {},
            "novelty_analysis": {
                "analysis": "æ–°é¢–æ€§åˆ†ææš‚æ—¶ä¸å¯ç”¨",
                "novelty_score": 70,
                "risk_level": "ä¸­ç­‰",
                "improvement_suggestions": ["éœ€è¦è¿›ä¸€æ­¥åˆ†æ"],
                "timestamp": datetime.now().isoformat()
            },
            "inventiveness_analysis": {
                "analysis": "åˆ›é€ æ€§åˆ†ææš‚æ—¶ä¸å¯ç”¨",
                "inventiveness_score": 75,
                "problem_difficulty": "ä¸­ç­‰",
                "improvement_suggestions": ["éœ€è¦è¿›ä¸€æ­¥åˆ†æ"],
                "timestamp": datetime.now().isoformat()
            },
            "utility_analysis": {
                "analysis": "å®ç”¨æ€§åˆ†ææš‚æ—¶ä¸å¯ç”¨",
                "utility_score": 80,
                "feasibility": "ä¸­ç­‰",
                "market_potential": "ä¸€èˆ¬",
                "improvement_suggestions": ["éœ€è¦è¿›ä¸€æ­¥åˆ†æ"],
                "timestamp": datetime.now().isoformat()
            },
            "critical_analysis": {
                "analysis": "æ‰¹åˆ¤æ€§åˆ†ææš‚æ—¶ä¸å¯ç”¨",
                "critical_score": 65,
                "risk_level": "ä¸­ç­‰",
                "implementation_difficulty": "ä¸­ç­‰",
                "improvement_space": "ä¸€èˆ¬",
                "improvement_suggestions": ["éœ€è¦è¿›ä¸€æ­¥åˆ†æ"],
                "timestamp": datetime.now().isoformat()
            },
            "improvement_suggestions": {
                "suggestions": "æ”¹è¿›å»ºè®®æš‚æ—¶ä¸å¯ç”¨",
                "priority_levels": ["éœ€è¦è¿›ä¸€æ­¥åˆ†æ"],
                "expected_effects": ["éœ€è¦è¿›ä¸€æ­¥åˆ†æ"],
                "implementation_steps": ["éœ€è¦è¿›ä¸€æ­¥åˆ†æ"],
                "timestamp": datetime.now().isoformat()
            },
            "overall_assessment": {
                "assessment": "æ€»ä½“è¯„ä¼°æš‚æ—¶ä¸å¯ç”¨",
                "overall_score": 70,
                "quality_grade": "C",
                "risk_level": "ä¸­ç­‰",
                "improvement_potential": "ä¸€èˆ¬",
                "market_prospect": "ä¸€èˆ¬",
                "application_recommendation": "éœ€è¦è¿›ä¸€æ­¥åˆ†æ",
                "decision_suggestion": "éœ€è¦è¿›ä¸€æ­¥åˆ†æ",
                "next_actions": ["éœ€è¦è¿›ä¸€æ­¥åˆ†æ"],
                "timestamp": datetime.now().isoformat()
            }
        }
    
    async def close(self):
        """å…³é—­èµ„æº"""
        await self.searcher.close()

async def test_enhanced_reviewer():
    """æµ‹è¯•å¢å¼ºç‰ˆå®¡æ ¸æ™ºèƒ½ä½“"""
    
    # åˆå§‹åŒ–å¢å¼ºç‰ˆå®¡æ ¸æ™ºèƒ½ä½“
    enhanced_reviewer = SimpleEnhancedReviewer()
    
    # æµ‹è¯•æ•°æ®
    topic = "åŸºäºè¯­ä¹‰ç†è§£çš„å¤æ‚å‡½æ•°å‚æ•°æ™ºèƒ½æ¨æ–­ä¸åˆ†å±‚è°ƒç”¨é‡è¯•ä¼˜åŒ–æ–¹æ³•"
    
    # æ¨¡æ‹Ÿç¬¬ä¸‰ç« å†…å®¹ï¼ˆç°æœ‰æŠ€æœ¯ï¼‰
    chapter_3_content = """
    ç¬¬ä¸‰ç«  ç°æœ‰æŠ€æœ¯
    
    ç›®å‰ï¼Œåœ¨æ™ºèƒ½å‡½æ•°è°ƒç”¨é¢†åŸŸå­˜åœ¨ä»¥ä¸‹ä¸»è¦æŠ€æœ¯ï¼š
    
    1. ä¼ ç»Ÿå‡½æ•°è°ƒç”¨æ–¹æ³•
    - åŸºäºå›ºå®šå‚æ•°åˆ—è¡¨çš„è°ƒç”¨æ–¹å¼
    - ç¼ºä¹æ™ºèƒ½æ¨æ–­èƒ½åŠ›
    - é”™è¯¯å¤„ç†æœºåˆ¶ç®€å•
    
    2. ç°æœ‰æ™ºèƒ½è°ƒç”¨æŠ€æœ¯
    - åŸºäºè§„åˆ™çš„æ¨¡å¼åŒ¹é…
    - ç®€å•çš„å‚æ•°æ¨æ–­
    - æœ‰é™çš„é”™è¯¯æ¢å¤èƒ½åŠ›
    
    3. ç›¸å…³ä¸“åˆ©æŠ€æœ¯
    - US12345678: æ™ºèƒ½å‡½æ•°è°ƒç”¨ç³»ç»Ÿ
    - CN98765432: å‚æ•°æ¨æ–­æ–¹æ³•
    """
    
    # æ¨¡æ‹Ÿç¬¬å››ç« å†…å®¹ï¼ˆæŠ€æœ¯é—®é¢˜ï¼‰
    chapter_4_content = """
    ç¬¬å››ç«  æŠ€æœ¯é—®é¢˜
    
    ç°æœ‰æŠ€æœ¯å­˜åœ¨ä»¥ä¸‹ä¸»è¦é—®é¢˜ï¼š
    
    1. å‚æ•°æ¨æ–­å‡†ç¡®ç‡ä½
    - å¤æ‚å‚æ•°ç±»å‹æ¨æ–­å›°éš¾
    - ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›æœ‰é™
    - å¤šå‚æ•°ç»„åˆæ¨æ–­æ•ˆæœå·®
    
    2. é”™è¯¯å¤„ç†æœºåˆ¶ä¸å®Œå–„
    - å¤±è´¥é‡è¯•ç­–ç•¥ç®€å•
    - ç¼ºä¹æ™ºèƒ½è¯Šæ–­èƒ½åŠ›
    - æ¢å¤æˆåŠŸç‡ä½
    
    3. ç³»ç»Ÿæ€§èƒ½é—®é¢˜
    - è°ƒç”¨å»¶è¿Ÿé«˜
    - èµ„æºæ¶ˆè€—å¤§
    - æ‰©å±•æ€§å·®
    """
    
    # æ¨¡æ‹Ÿç¬¬äº”ç« å†…å®¹ï¼ˆæŠ€æœ¯æ–¹æ¡ˆï¼‰
    chapter_5_content = """
    ç¬¬äº”ç«  æŠ€æœ¯æ–¹æ¡ˆè¯¦ç»†é˜è¿°
    
    5.1 ç³»ç»Ÿæ¶æ„è®¾è®¡
    
    æœ¬å‘æ˜é‡‡ç”¨åˆ†å±‚æ¶æ„è®¾è®¡ï¼ŒåŒ…æ‹¬ï¼š
    - è¯­ä¹‰ç†è§£å±‚ï¼šè´Ÿè´£è‡ªç„¶è¯­è¨€è§£æ
    - å‚æ•°æ¨æ–­å±‚ï¼šå®ç°æ™ºèƒ½å‚æ•°æ¨æ–­
    - è°ƒç”¨æ‰§è¡Œå±‚ï¼šæ‰§è¡Œå‡½æ•°è°ƒç”¨
    - é‡è¯•ä¼˜åŒ–å±‚ï¼šå¤„ç†å¤±è´¥é‡è¯•
    
    5.2 æ ¸å¿ƒç®—æ³•å®ç°
    
    åˆ›æ–°ç®—æ³•åŒ…æ‹¬ï¼š
    - è¯­ä¹‰ç†è§£ç®—æ³•ï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªç„¶è¯­è¨€å¤„ç†
    - å‚æ•°æ¨æ–­ç®—æ³•ï¼šå¤šç»´åº¦å‚æ•°æ™ºèƒ½æ¨æ–­
    - é‡è¯•ä¼˜åŒ–ç®—æ³•ï¼šè‡ªé€‚åº”é‡è¯•ç­–ç•¥
    
    5.3 æ•°æ®æµç¨‹è®¾è®¡
    
    æ•°æ®å¤„ç†æµç¨‹ï¼š
    - è¾“å…¥é¢„å¤„ç†
    - è¯­ä¹‰åˆ†æ
    - å‚æ•°æ¨æ–­
    - è°ƒç”¨æ‰§è¡Œ
    - ç»“æœéªŒè¯
    - å¤±è´¥é‡è¯•
    """
    
    # æ¨¡æ‹Ÿæ£€ç´¢ç»“æœ
    search_results = {
        "æ™ºèƒ½å‡½æ•°è°ƒç”¨": [
            {"title": "æ™ºèƒ½å‡½æ•°è°ƒç”¨æŠ€æœ¯", "content": "ç›¸å…³æŠ€æœ¯å†…å®¹"},
            {"title": "å‚æ•°æ¨æ–­æ–¹æ³•", "content": "ç°æœ‰æ¨æ–­æŠ€æœ¯"}
        ],
        "é‡è¯•æœºåˆ¶": [
            {"title": "å¤±è´¥é‡è¯•ç­–ç•¥", "content": "ç°æœ‰é‡è¯•æŠ€æœ¯"},
            {"title": "é”™è¯¯æ¢å¤æ–¹æ³•", "content": "æ¢å¤æœºåˆ¶ç ”ç©¶"}
        ]
    }
    
    try:
        logger.info("ğŸš€ å¼€å§‹æµ‹è¯•å¢å¼ºç‰ˆå®¡æ ¸æ™ºèƒ½ä½“")
        
        # æ‰§è¡Œç»¼åˆå®¡æ ¸
        review_results = await enhanced_reviewer.comprehensive_review(
            chapter_3_content=chapter_3_content,
            chapter_4_content=chapter_4_content,
            chapter_5_content=chapter_5_content,
            topic=topic,
            search_results=search_results
        )
        
        logger.info("âœ… ç»¼åˆå®¡æ ¸å®Œæˆ")
        
        # è¾“å‡ºå®¡æ ¸ç»“æœ
        print("\n" + "="*80)
        print("å¢å¼ºç‰ˆå®¡æ ¸æ™ºèƒ½ä½“æµ‹è¯•ç»“æœ")
        print("="*80)
        
        # æ·±åº¦æ£€ç´¢ç»“æœ
        print("\nğŸ” æ·±åº¦æ£€ç´¢ç»“æœ:")
        deep_search = review_results.get("deep_search_results", {})
        for keyword, results in deep_search.items():
            print(f"  - {keyword}: {len(results)} æ¡ç»“æœ")
        
        # æ–°é¢–æ€§åˆ†æ
        print("\nğŸ“‹ æ–°é¢–æ€§åˆ†æ:")
        novelty = review_results.get("novelty_analysis", {})
        print(f"  - è¯„åˆ†: {novelty.get('novelty_score', 'N/A')}")
        print(f"  - é£é™©ç­‰çº§: {novelty.get('risk_level', 'N/A')}")
        print(f"  - åˆ†æ: {novelty.get('analysis', 'N/A')}")
        
        # åˆ›é€ æ€§åˆ†æ
        print("\nğŸ’¡ åˆ›é€ æ€§åˆ†æ:")
        inventiveness = review_results.get("inventiveness_analysis", {})
        print(f"  - è¯„åˆ†: {inventiveness.get('inventiveness_score', 'N/A')}")
        print(f"  - é—®é¢˜éš¾åº¦: {inventiveness.get('problem_difficulty', 'N/A')}")
        print(f"  - åˆ†æ: {inventiveness.get('analysis', 'N/A')}")
        
        # å®ç”¨æ€§åˆ†æ
        print("\nğŸ”§ å®ç”¨æ€§åˆ†æ:")
        utility = review_results.get("utility_analysis", {})
        print(f"  - è¯„åˆ†: {utility.get('utility_score', 'N/A')}")
        print(f"  - å¯è¡Œæ€§: {utility.get('feasibility', 'N/A')}")
        print(f"  - åˆ†æ: {utility.get('analysis', 'N/A')}")
        
        # æ‰¹åˆ¤æ€§åˆ†æ
        print("\nğŸ¤” æ‰¹åˆ¤æ€§åˆ†æ:")
        critical = review_results.get("critical_analysis", {})
        print(f"  - è¯„åˆ†: {critical.get('critical_score', 'N/A')}")
        print(f"  - é£é™©ç­‰çº§: {critical.get('risk_level', 'N/A')}")
        print(f"  - åˆ†æ: {critical.get('analysis', 'N/A')}")
        
        # æ€»ä½“è¯„ä¼°
        print("\nğŸ“Š æ€»ä½“è¯„ä¼°:")
        overall = review_results.get("overall_assessment", {})
        print(f"  - ç»¼åˆè¯„åˆ†: {overall.get('overall_score', 'N/A')}")
        print(f"  - è´¨é‡ç­‰çº§: {overall.get('quality_grade', 'N/A')}")
        print(f"  - ç”³è¯·å»ºè®®: {overall.get('application_recommendation', 'N/A')}")
        print(f"  - åˆ†æ: {overall.get('assessment', 'N/A')}")
        
        # æ”¹è¿›å»ºè®®
        print("\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        improvements = review_results.get("improvement_suggestions", {})
        suggestions = improvements.get("suggestions", "æš‚æ— å…·ä½“å»ºè®®")
        print(f"  - {suggestions}")
        
        print("\n" + "="*80)
        print("æµ‹è¯•å®Œæˆ")
        print("="*80)
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print(f"æµ‹è¯•å¤±è´¥: {e}")
    
    finally:
        # å…³é—­èµ„æº
        await enhanced_reviewer.close()

async def test_duckduckgo_search():
    """æµ‹è¯•DuckDuckGoæ£€ç´¢åŠŸèƒ½"""
    
    searcher = SimpleDuckDuckGoSearcher()
    
    try:
        logger.info("ğŸ” æµ‹è¯•DuckDuckGoæ£€ç´¢åŠŸèƒ½")
        
        # æµ‹è¯•æ£€ç´¢
        query = "æ™ºèƒ½å‡½æ•°è°ƒç”¨ ä¸“åˆ© æŠ€æœ¯æ–¹æ¡ˆ"
        results = await searcher.search(query, max_results=5)
        
        print(f"\næ£€ç´¢æŸ¥è¯¢: {query}")
        print(f"æ£€ç´¢ç»“æœæ•°é‡: {len(results)}")
        
        for i, result in enumerate(results, 1):
            print(f"\nç»“æœ {i}:")
            print(f"  æ ‡é¢˜: {result.get('title', 'N/A')}")
            print(f"  æ¥æº: {result.get('source', 'N/A')}")
            print(f"  å†…å®¹: {result.get('content', 'N/A')[:100]}...")
        
    except Exception as e:
        logger.error(f"âŒ DuckDuckGoæ£€ç´¢æµ‹è¯•å¤±è´¥: {e}")
        print(f"DuckDuckGoæ£€ç´¢æµ‹è¯•å¤±è´¥: {e}")
    
    finally:
        await searcher.close()

if __name__ == "__main__":
    print("ğŸ§ª å¼€å§‹æµ‹è¯•å¢å¼ºç‰ˆå®¡æ ¸æ™ºèƒ½ä½“")
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_enhanced_reviewer())
    
    print("\n" + "-"*80)
    
    # æµ‹è¯•DuckDuckGoæ£€ç´¢
    asyncio.run(test_duckduckgo_search())