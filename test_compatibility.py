#!/usr/bin/env python3
"""
æµ‹è¯•è¿­ä»£å¼æ£€ç´¢ç»“æœä¸åç»­æ™ºèƒ½ä½“çš„å…¼å®¹æ€§
"""
import asyncio
import logging
from unified_service import conduct_prior_art_search, _ensure_search_results_compatibility

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def test_compatibility():
    """æµ‹è¯•å…¼å®¹æ€§"""
    try:
        logger.info("ğŸš€ å¼€å§‹æµ‹è¯•è¿­ä»£å¼æ£€ç´¢ç»“æœå…¼å®¹æ€§")
        
        # æ‰§è¡Œè¿­ä»£å¼æ£€ç´¢
        topic = "åŸºäºè¯­ä¹‰ç†è§£çš„å¤æ‚å‡½æ•°å‚æ•°æ™ºèƒ½æ¨æ–­ä¸åˆ†å±‚è°ƒç”¨é‡è¯•ä¼˜åŒ–æ–¹æ³•"
        keywords = ["è¯­ä¹‰ç†è§£", "å‚æ•°æ¨æ–­", "åˆ†å±‚è°ƒç”¨", "é‡è¯•ä¼˜åŒ–"]
        
        # è·å–åŸå§‹æ£€ç´¢ç»“æœ
        original_results = await conduct_prior_art_search(topic, keywords, {})
        logger.info(f"âœ… åŸå§‹æ£€ç´¢å®Œæˆï¼Œè·å¾— {len(original_results)} ä¸ªç»“æœ")
        
        # æ£€æŸ¥åŸå§‹ç»“æœç»“æ„
        logger.info("ğŸ“‹ åŸå§‹ç»“æœç»“æ„æ£€æŸ¥:")
        for i, result in enumerate(original_results[:2]):
            logger.info(f"  ç»“æœ {i+1} å­—æ®µ: {list(result.keys())}")
        
        # åº”ç”¨å…¼å®¹æ€§è½¬æ¢
        compatible_results = _ensure_search_results_compatibility(original_results)
        logger.info(f"âœ… å…¼å®¹æ€§è½¬æ¢å®Œæˆï¼Œ{len(compatible_results)} ä¸ªç»“æœå·²æ ‡å‡†åŒ–")
        
        # æ£€æŸ¥å…¼å®¹ç»“æœç»“æ„
        logger.info("ğŸ“‹ å…¼å®¹ç»“æœç»“æ„æ£€æŸ¥:")
        for i, result in enumerate(compatible_results[:2]):
            logger.info(f"  ç»“æœ {i+1} å­—æ®µ: {list(result.keys())}")
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ["patent_id", "title", "abstract", "filing_date", "publication_date", "assignee", "relevance_score", "similarity_analysis"]
        missing_fields = []
        
        for i, result in enumerate(compatible_results):
            for field in required_fields:
                if field not in result:
                    missing_fields.append(f"ç»“æœ{i+1}ç¼ºå°‘{field}")
        
        if missing_fields:
            logger.warning(f"âš ï¸ å‘ç°ç¼ºå¤±å­—æ®µ: {missing_fields}")
        else:
            logger.info("âœ… æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨")
        
        # éªŒè¯GLMå¢å¼ºå­—æ®µ
        glm_enhanced_count = sum(1 for r in compatible_results if r.get("enhanced_by_glm", False))
        logger.info(f"âœ… GLMå¢å¼ºç»“æœæ•°é‡: {glm_enhanced_count}")
        
        # æ¨¡æ‹Ÿåç»­æ™ºèƒ½ä½“çš„ä½¿ç”¨
        logger.info("ğŸ” æ¨¡æ‹Ÿåç»­æ™ºèƒ½ä½“ä½¿ç”¨:")
        search_results = {
            "query": {"topic": topic, "keywords": keywords},
            "results": compatible_results,
            "analysis": {"total_patents_found": len(compatible_results)},
            "recommendations": ["å»ºè®®1", "å»ºè®®2"]
        }
        
        # æ¨¡æ‹ŸDiscussion Agentçš„è®¿é—®æ¨¡å¼
        search_findings = search_results.get("results", [])
        logger.info(f"âœ… Discussion Agentå¯ä»¥è®¿é—®: {len(search_findings)} ä¸ªä¸“åˆ©")
        
        # æ¨¡æ‹ŸWriter Agentçš„è®¿é—®æ¨¡å¼
        for i, patent in enumerate(search_findings[:2]):
            logger.info(f"  ä¸“åˆ© {i+1}: {patent.get('title', 'N/A')} - ç›¸å…³æ€§: {patent.get('relevance_score', 'N/A')}")
            if patent.get("enhanced_by_glm"):
                logger.info(f"    GLMåˆ†æ: {patent.get('glm_analysis', 'N/A')[:100]}...")
        
        return compatible_results
        
    except Exception as e:
        logger.error(f"âŒ å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    try:
        results = asyncio.run(test_compatibility())
        print(f"\nğŸ‰ å…¼å®¹æ€§æµ‹è¯•æˆåŠŸï¼")
        print(f"ğŸ“Š ç»“æœç»Ÿè®¡:")
        print(f"  - æ€»ç»“æœæ•°: {len(results)}")
        print(f"  - GLMå¢å¼º: {sum(1 for r in results if r.get('enhanced_by_glm', False))}")
        print(f"  - å­—æ®µå®Œæ•´æ€§: âœ… æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨")
    except Exception as e:
        print(f"\nğŸ’¥ å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()